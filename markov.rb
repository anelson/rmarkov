
class Markov
    NONWORD = "####"

    def initialize(order)
        @words = Hash.new
        @order = order
    end

    def learn(text) 
        word_list = tokenize_text(text);

        #Pad 'words' with the NONWORD char to get things rolling
        @order.times do
            word_list.insert(0, NONWORD)
        end

        #Append with NONWORD to terminate
        word_list << NONWORD

        word_list.each_with_index do |word, index| 
            learn_word(word_list[index - @order, @order + 1]) unless index < @order
        end
    end

    def generate
        #Start by picking a random state starting with NONWORD
        state = generate_initial_state()
        output = Array.new

        output << generate_word(state) while state[@order - 1] != NONWORD

        return output.join(" ")
    end

    def get_states
        return @words
    end

    def generate_initial_state()
        # Build an array of @order elements, containing a randomly-selected starting sequence.
        state = Array.new

        current_word = @words

        @order.times do
            # Pick a random key from the keys in hash table current_word, then
            # look up the value in current_word corresponding to that key
            rand_key = current_word.keys[rand(current_word.keys.length)]

            current_word = current_word[rand_key]

            # rand_key is a word which occurred in the training corpus, and which forms
            # part of the state
            state << rand_key
        end

        state
    end

    def generate_word(state)
        # State is an array of @order elements reflecting the last @order words generated by the
        # generator.  Shift the array so element 0 falls off and the rest of the elements shift
        # left by once place; the fallen-off element 0 is the next word generated.
        #
        # Append a new word to the end of the array based on the state transition probabilities
        # for the words in the array
        state << generate_next_word(state)

        # 'pop' the left-most word off the state and return it
        return state.shift
    end

    def generate_next_word(state)
        # Given an @order-element state, generates another word consistent with the state transition
        # probabilities
        current_word = @words

        if state.length != @order  
            raise ArgumentError, "Word state has an incorrect number of elements, #{state.length} (should be #{@order})", caller
        end

        state.each do |word|
            if !current_word.include?(word)
                raise ArgumentError, "Word state [#{state.join(',')}] isn't a valid tuple"
            end
            current_word = current_word[word]
        end

        # current_word is now an array of possible next works.  Just pick one at random
        return current_word[rand(current_word.length)]
    end

    def tokenize_text(text)
        # Split text into an array of words on whitespace
        words = text.split(/\s+/)

        words
    end

    def learn_word(wordStates)
        #wordStates[wordStates.length-1] is the word to learn; the preceeding word(s) are used to build the Markov chain
        puts "Learning #{wordStates.join(',')}"

        current_word = @words
        wordStates.each_with_index do |word, index|
            puts "#{word}"

            if index < @order - 1
                current_word[word] ||= {}
                current_word = current_word[word]
            elsif index == @order - 1
                current_word[word] ||= []
                current_word = current_word[word]
            else
                current_word << word
            end
        end
    end
end
